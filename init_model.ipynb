{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "NYC on 2024-03-04 09:55:49.469730\n",
      "NYC Max Temperature: 56.03\n",
      "----------\n",
      "----------\n",
      "Chicago on 2024-03-04 09:55:49.528135\n",
      "Chicago Max Temperature: 62.11\n",
      "----------\n",
      "----------\n",
      "Miami on 2024-03-04 09:55:49.651068\n",
      "Miami Max Temperature: 79.02\n",
      "----------\n",
      "----------\n",
      "Austin on 2024-03-04 09:55:49.723045\n",
      "Austin Max Temperature: 72.19\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "\n",
    "NYC Elev: 154.0 ft; Lat/Lon: 40.78333°N / -73.96667°W\n",
    "Chi Lat: 41.78°N Lon: -87.76°W Elev: 617ft.\n",
    "Miami Lat: 25.79°N Lon: -80.32°W Elev: 10ft.\n",
    "Austin Lat: 30.18°N Lon: -97.68°W Elev: 486ft. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# day 1 - just making API call and taking that choice\n",
    "import http.client\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_weather(city_name, latitude, longitude):\n",
    "    conn = http.client.HTTPSConnection(\"api.openweathermap.org\")\n",
    "    payload = ''\n",
    "    headers = {}\n",
    "\n",
    "    print('----------')\n",
    "    print(f'{city_name} on {datetime.now()}')\n",
    "    conn.request(\"GET\", f\"/data/2.5/weather?lat={latitude}&lon={longitude}&appid=3f4c2b994a539c4372210a46131f36e2&units=imperial\", payload, headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read().decode('utf-8')\n",
    "\n",
    "    # Parsing JSON data\n",
    "    json_data = json.loads(data)\n",
    "\n",
    "    # Extracting temp_max from the parsed JSON data\n",
    "    temp_max = json_data[\"main\"][\"temp_max\"]\n",
    "\n",
    "    print(f'{city_name} Max Temperature:', temp_max)\n",
    "    print('----------')\n",
    "\n",
    "# NYC\n",
    "get_weather('NYC', 40.783, -73.96)\n",
    "\n",
    "# Chicago\n",
    "get_weather('Chicago', 41.78, -87.76)\n",
    "\n",
    "# Miami\n",
    "get_weather('Miami', 25.79, -80.32)\n",
    "\n",
    "# Austin\n",
    "get_weather('Austin', 30.18, -97.68)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying tomorrow io api\n",
    "\n",
    "\n",
    "import http.client\n",
    "\n",
    "conn = http.client.HTTPSConnection(\"api.tomorrow.io\")\n",
    "payload = ''\n",
    "headers = {}\n",
    "conn.request(\"GET\", \"/v4/weather/forecast?apikey=zITDa7BozjihbZ481cr0ecmAr7addQ1h&location=42.3478,%20-71.0466&timestep=1h\", payload, headers)\n",
    "res = conn.getresponse()\n",
    "data = res.read().decode('utf-8')\n",
    "#print(data)\n",
    "\n",
    "# Parsing JSON data\n",
    "json_data = json.loads(data)\n",
    "\n",
    "    # Save the JSON data to a file\n",
    "filename = 'test_weather_data.json'\n",
    "with open(filename, 'w') as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)\n",
    "    print(f'Data saved to {filename}')\n",
    "#print(json_data['timelines']['daily']['temperatureMax'])\n",
    "\n",
    "# finding the best way to get out the json I need\n",
    "# Specify the file name or path\n",
    "filename_nyc = 'test_weather_data.json'\n",
    "\n",
    "# Load JSON data from the file\n",
    "with open(filename_nyc, 'r') as json_file:\n",
    "    nyc_weather_data = json.load(json_file)\n",
    "\n",
    "\n",
    "print(nyc_weather_data['timelines']['daily'][0]['values']['temperatureMax'])\n",
    "\n",
    "# Now you can use nyc_weather_data in the current cell\n",
    "#print(\"NYC Weather Data:\")\n",
    "#print(json.dumps(nyc_weather_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "NYC on 2024-03-05 15:37:08.283765\n",
      "NYC Max Temperature: 7.83\n",
      "----------\n",
      "----------\n",
      "Chicago on 2024-03-05 15:37:09.040025\n",
      "Chicago Max Temperature: 5.88\n",
      "----------\n",
      "----------\n",
      "Miami on 2024-03-05 15:37:09.765081\n",
      "Miami Max Temperature: 28\n",
      "----------\n",
      "----------\n",
      "Austin on 2024-03-05 15:37:10.467977\n",
      "Austin Max Temperature: 31.69\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import http.client\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def get_weather_tomorrow_io(city_name, latitude, longitude):\n",
    "    conn = http.client.HTTPSConnection(\"api.tomorrow.io\")\n",
    "    payload = ''\n",
    "    headers = {}\n",
    "\n",
    "    print('----------')\n",
    "    print(f'{city_name} on {datetime.now()}')\n",
    "    conn.request(\"GET\", f\"/v4/weather/forecast?apikey=zITDa7BozjihbZ481cr0ecmAr7addQ1h&location={latitude},{longitude}&timestep=1h\", payload, headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read().decode('utf-8')\n",
    "\n",
    "    # Parsing JSON data\n",
    "    json_data = json.loads(data)\n",
    "    temperature_max = json_data['timelines']['daily'][0]['values']['temperatureMax']\n",
    "\n",
    "    print(f'{city_name} Max Temperature:', temperature_max)\n",
    "    print('----------')\n",
    "\n",
    "# NYC\n",
    "get_weather_tomorrow_io('NYC', 40.783, -73.96)\n",
    "\n",
    "# Chicago\n",
    "get_weather_tomorrow_io('Chicago', 41.78, -87.76)\n",
    "\n",
    "# Miami\n",
    "get_weather_tomorrow_io('Miami', 25.79, -80.32)\n",
    "\n",
    "# Austin\n",
    "get_weather_tomorrow_io('Austin', 30.18, -97.68)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes from 3.4 in class\n",
    "# need to go to website and web scrape public tables (if no API exists)\n",
    "# prob nede to consider relationship between wind, humidty, etc. \n",
    "# more features prob means more accurate \n",
    "# combine with prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed for chi_april_2023.pdf. CSV file saved as chi_april_2023.csv\n",
      "Conversion completed for austin_april_2023.pdf. CSV file saved as austin_april_2023.csv\n",
      "Conversion completed for austin_march_2023.pdf. CSV file saved as austin_march_2023.csv\n",
      "Conversion completed for chi_march_2023.pdf. CSV file saved as chi_march_2023.csv\n",
      "Conversion completed for miami_feb_2024.pdf. CSV file saved as miami_feb_2024.csv\n",
      "Conversion completed for austin_max.pdf. CSV file saved as austin_max.csv\n",
      "Conversion completed for austin_feb_2024.pdf. CSV file saved as austin_feb_2024.csv\n",
      "Conversion completed for miami_max.pdf. CSV file saved as miami_max.csv\n",
      "Conversion completed for centralpark_march_2023.pdf. CSV file saved as centralpark_march_2023.csv\n",
      "Conversion completed for chi_feb_2024.pdf. CSV file saved as chi_feb_2024.csv\n",
      "Conversion completed for centralpark_april_2023.pdf. CSV file saved as centralpark_april_2023.csv\n",
      "Conversion completed for centralpark_max.pdf. CSV file saved as centralpark_max.csv\n",
      "Conversion completed for centralpark_feb_2024.pdf. CSV file saved as centralpark_feb_2024.csv\n",
      "Conversion completed for chi_max.pdf. CSV file saved as chi_max.csv\n",
      "Conversion completed for miami_march_2023.pdf. CSV file saved as miami_march_2023.csv\n",
      "Conversion completed for miami_april_2023.pdf. CSV file saved as miami_april_2023.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import camelot\n",
    "import pandas as pd\n",
    "\n",
    "# Replace 'pdf_folder' with the path to your folder containing PDFs\n",
    "pdf_folder = '/Users/samdvorin/Desktop/code/542/weather-prediction/weather data'\n",
    "\n",
    "# Iterate through all PDF files in the folder\n",
    "for pdf_path in os.listdir(pdf_folder):\n",
    "    if pdf_path.endswith(\".pdf\"):\n",
    "        # Use camelot to extract tables from PDF\n",
    "        tables = camelot.read_pdf(os.path.join(pdf_folder, pdf_path), flavor='stream', pages='all')\n",
    "\n",
    "        # Concatenate tables into a single DataFrame\n",
    "        df = pd.concat([table.df for table in tables], ignore_index=True)\n",
    "\n",
    "        # Create a CSV file name based on the PDF file name\n",
    "        csv_output = os.path.splitext(pdf_path)[0] + '.csv'\n",
    "\n",
    "        # Save DataFrame to CSV\n",
    "        df.to_csv(csv_output, index=False)\n",
    "\n",
    "        print(f\"Conversion completed for {pdf_path}. CSV file saved as {csv_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Date</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDD</td>\n",
       "      <td>CDD</td>\n",
       "      <td>Precipitation</td>\n",
       "      <td>New Snow</td>\n",
       "      <td>Snow Depth</td>\n",
       "      <td>30.18</td>\n",
       "      <td>-97.68</td>\n",
       "      <td>486</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Maximum</td>\n",
       "      <td>Minimum</td>\n",
       "      <td>Average</td>\n",
       "      <td>Departure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.18</td>\n",
       "      <td>-97.68</td>\n",
       "      <td>486</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>81</td>\n",
       "      <td>44</td>\n",
       "      <td>62.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.18</td>\n",
       "      <td>-97.68</td>\n",
       "      <td>486</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>84</td>\n",
       "      <td>54</td>\n",
       "      <td>69.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.18</td>\n",
       "      <td>-97.68</td>\n",
       "      <td>486</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>90</td>\n",
       "      <td>69</td>\n",
       "      <td>79.5</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.18</td>\n",
       "      <td>-97.68</td>\n",
       "      <td>486</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1        2        3          4    5    6              7  \\\n",
       "0        Date      NaN      NaN      NaN        NaN  HDD  CDD  Precipitation   \n",
       "1         NaN  Maximum  Minimum  Average  Departure  NaN  NaN            NaN   \n",
       "2  2023-04-01       81       44     62.5       -2.4    2    0           0.00   \n",
       "3  2023-04-02       84       54     69.0        3.8    0    4           0.00   \n",
       "4  2023-04-03       90       69     79.5       14.1    0   15           0.00   \n",
       "\n",
       "          8           9    Lat    Lon  Elevation    City  \n",
       "0  New Snow  Snow Depth  30.18 -97.68        486  Austin  \n",
       "1       NaN         NaN  30.18 -97.68        486  Austin  \n",
       "2       0.0           0  30.18 -97.68        486  Austin  \n",
       "3       0.0           0  30.18 -97.68        486  Austin  \n",
       "4       0.0           0  30.18 -97.68        486  Austin  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/Users/samdvorin/Desktop/code/542/weather-prediction/csvs/austin_april_2023.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.drop([0, 1])\n",
    "\n",
    "# Resetting the index after dropping rows\n",
    "df = df.reset_index(drop=True)\n",
    "df['Lat'] = 30.18\n",
    "df['Lon'] = -97.68\n",
    "df['Elevation'] = 486\n",
    "df['City'] = 'Austin'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the directory path containing your CSV files\n",
    "directory_path = \"/Users/samdvorin/Desktop/code/542/weather-prediction/csvs\"\n",
    "\n",
    "# List of city information\n",
    "cities_info = {\n",
    "    'centralpark': {'Lat': 40.78333, 'Lon': -73.96667, 'Elevation': 154, 'City': 'Central Park'},\n",
    "    'chi': {'Lat': 41.78, 'Lon': -87.76, 'Elevation': 617, 'City': 'Chicago'},\n",
    "    'miami': {'Lat': 25.79, 'Lon': -80.32, 'Elevation': 10, 'City': 'Miami'},\n",
    "    'austin': {'Lat': 30.18, 'Lon': -97.68, 'Elevation': 486, 'City': 'Austin'}\n",
    "}\n",
    "\n",
    "# List to store individual DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each CSV file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.iloc[:-12]\n",
    "\n",
    "\n",
    "\n",
    "        # Extract the city from the filename\n",
    "        city = filename.split('_')[0]\n",
    "\n",
    "        # Add columns for latitude, longitude, elevation, and city\n",
    "        df['Lat'] = cities_info[city]['Lat']\n",
    "        df['Lon'] = cities_info[city]['Lon']\n",
    "        df['Elevation'] = cities_info[city]['Elevation']\n",
    "        df['City'] = cities_info[city]['City']\n",
    "        \n",
    "\n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "combined_df = combined_df.dropna()\n",
    "\n",
    "# Reset the index\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "new_column_names = ['Date', 'Maximum', 'Minimum', 'Average', 'Departure', 'HDD', 'CDD', 'Precipitation', 'New Snow', 'Snow Depth', 'Lat', 'Lon', 'Elevation', 'City']\n",
    "\n",
    "# Replace the first row with the new column names\n",
    "combined_df.columns = new_column_names\n",
    "\n",
    "\n",
    "\n",
    "#['Date', 'Maximum', 'Minimum', 'Average', 'Departure', 'HDD', 'CDD', 'Precipitation', 'New Snow', 'Snow Depth', 'Lat', 'Lon', 'Elevation', 'City']\n",
    "output_file_path = \"output_file.csv\"\n",
    "combined_df.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8433822212b79f5d8b3452ec504986410bf31415c55c9cbd3d55cd029f0ca8d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
