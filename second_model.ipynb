{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome in headless mode (without a graphical user interface)\n",
    "chrome_service = ChromeService(executable_path='/Users/samdvorin/Desktop/code/542/weather-prediction/chromedriver')  # Replace with the path to your chromedriver executable\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "url = 'https://www.wunderground.com/history/daily/us/ny/new-york-city/KLGA/date/2024-3-1'\n",
    "driver.get(url)\n",
    "\n",
    "# Locate the table element at the bottom of the page using your specified XPath\n",
    "table_element = driver.find_element('xpath', '/html/body/app-root/app-history/one-column-layout/wu-header/sidenav/mat-sidenav-container/mat-sidenav-content/div[2]/section/div[2]/div[1]/div[5]/div[1]/div/lib-city-history-observation/div/div[2]')\n",
    "\n",
    "# Extract the text from the table\n",
    "table_text = table_element.text\n",
    "print(\"Table at the bottom of the page:\\n\", table_text)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "copy_text = table_text\n",
    "\n",
    "with open(os.path.join(\"sampledata.txt\"), 'w') as file:\n",
    "    file.write(copy_text)\n",
    "print(copy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time am/pm  temp  dew point  humidity wind speed\n",
      "0  1:51    AM    33         11        40         13\n",
      "1  2:51    AM    32         11        42         13\n",
      "2  3:51    AM    32         10        40          9\n",
      "3  4:51    AM    31         11        43         13\n",
      "4  5:51    AM    31         11        43         10\n"
     ]
    }
   ],
   "source": [
    "# doesnt take no wind speed into account\n",
    "import pandas as pd\n",
    "\n",
    "# Read the text file and parse the data\n",
    "data = []\n",
    "with open('sampledata.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Split the line by spaces\n",
    "        parts = line.strip().split()\n",
    "\n",
    "        # Ensure that the line has the expected number of elements\n",
    "        if len(parts) >= 10:\n",
    "            # Extract the time, AM/PM, temperature, dew point, humidity, and wind speed\n",
    "            time = parts[0]\n",
    "            am_pm = parts[1]\n",
    "            temp = int(parts[2])\n",
    "            dew_point = int(parts[4])\n",
    "            humidity = int(parts[6])\n",
    "            wind_speed = parts[9]\n",
    "\n",
    "            # Append the parsed data to the list\n",
    "            data.append([time, am_pm, temp, dew_point, humidity, wind_speed])\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(data, columns=['time', 'am/pm', 'temp', 'dew point', 'humidity', 'wind speed'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     time am/pm  temp  dew point  humidity  wind speed\n",
      "0    1:51    AM    33         11        40          13\n",
      "1    2:51    AM    32         11        42          13\n",
      "2    3:51    AM    32         10        40           9\n",
      "3    4:51    AM    31         11        43          13\n",
      "4    5:51    AM    31         11        43          10\n",
      "5    6:51    AM    31         11        43           6\n",
      "6    7:51    AM    31         12        46           6\n",
      "7    8:51    AM    33         12        42           5\n",
      "8    9:51    AM    35         13        40           8\n",
      "9   10:51    AM    38         14        38           0\n",
      "10  11:51    AM    40         14        35           7\n",
      "11  12:51    PM    42         13        31           6\n",
      "12   1:51    PM    43         16        34          10\n",
      "13   2:51    PM    43         17        35          14\n",
      "14   3:51    PM    42         19        40          18\n",
      "15   4:51    PM    42         20        41          16\n",
      "16   5:51    PM    41         22        47          13\n",
      "17   6:51    PM    41         24        51          14\n",
      "18   7:51    PM    41         26        55          12\n",
      "19   8:51    PM    41         28        60          13\n",
      "20   9:51    PM    41         28        60          12\n",
      "21  10:51    PM    41         29        62           9\n",
      "22  11:51    PM    41         31        67          10\n",
      "23  12:51    AM    42         32        67           8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the text file and parse the data\n",
    "data = []\n",
    "with open('sampledata.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Split the line by spaces\n",
    "        parts = line.strip().split()\n",
    "\n",
    "        # Ensure that the line has the expected number of elements\n",
    "        if len(parts) >= 10:\n",
    "            # Extract the time, AM/PM, temperature, dew point, humidity, and wind speed\n",
    "            time = parts[0]\n",
    "            am_pm = parts[1]\n",
    "            temp = int(parts[2])\n",
    "            dew_point = int(parts[4])\n",
    "            humidity = int(parts[6])\n",
    "            # Check if wind speed is available\n",
    "            wind_speed_index = 9\n",
    "            if parts[wind_speed_index].isdigit():\n",
    "                wind_speed = int(parts[wind_speed_index])\n",
    "            else:\n",
    "                wind_speed = 0\n",
    "\n",
    "            # Append the parsed data to the list\n",
    "            data.append([time, am_pm, temp, dew_point, humidity, wind_speed])\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(data, columns=['time', 'am/pm', 'temp', 'dew point', 'humidity', 'wind speed'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head(24))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTDATED first try at converting to dataframe, ineffeicnt and converts to csv then back to dataframe\n",
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "#print(table_text)\n",
    "\n",
    "# Split the table text into rows\n",
    "rows = [row.split() for row in copy_text.strip().split('\\n')[10:]]\n",
    "# Specify the CSV file path\n",
    "csv_file_path = 'table_data.csv'\n",
    "\n",
    "# Write data to CSV file\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    \n",
    "    csv_writer.writerows(rows)\n",
    "\n",
    "print(f\"Data has been written to {csv_file_path}\")\n",
    "\n",
    "\n",
    "# Read the CSV file into a list of lines\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Modify each line to exclude the last value if it is the 19th value\n",
    "modified_lines = [','.join(line.split(',')[:-1]) + '\\n' if len(line.split(',')) == 19 else line for line in lines]\n",
    "\n",
    "# Save the modified content back to the CSV file\n",
    "with open(csv_file_path, 'w') as modified_file:\n",
    "    modified_file.writelines(modified_lines)\n",
    "\n",
    "\n",
    "# Read the CSV file into a DataFrame and drop the last column\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "#print(df.head())\n",
    "\n",
    "df = df.iloc[:, [0, 1, 2, 4, 6, 9]]\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# Create a new DataFrame with the column names as a row\n",
    "column_names_row = pd.DataFrame([column_names], columns=df.columns)\n",
    "\n",
    "# Concatenate the new row to the top of the original DataFrame\n",
    "df_with_column_names = pd.concat([column_names_row, df]).reset_index(drop=True)\n",
    "df_with_column_names.columns = ['time', 'am/pm', 'temp', 'dew point', 'humidity', 'wind speed']\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df_with_column_names.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for 2024-02-19...\n",
      "Data for 2024-02-19 scraped and saved in 128.53 seconds\n",
      "Scraping data for 2024-02-20...\n",
      "Data for 2024-02-20 scraped and saved in 121.15 seconds\n",
      "Scraping data for 2024-02-21...\n",
      "Data for 2024-02-21 scraped and saved in 120.94 seconds\n",
      "Scraping data for 2024-02-22...\n",
      "Data for 2024-02-22 scraped and saved in 130.76 seconds\n",
      "Scraping data for 2024-02-23...\n",
      "Data for 2024-02-23 scraped and saved in 259.79 seconds\n",
      "Scraping data for 2024-02-24...\n",
      "Data for 2024-02-24 scraped and saved in 119.16 seconds\n",
      "Scraping data for 2024-02-25...\n",
      "Data for 2024-02-25 scraped and saved in 133.62 seconds\n",
      "Scraping data for 2024-02-26...\n",
      "Data for 2024-02-26 scraped and saved in 119.25 seconds\n",
      "Scraping data for 2024-02-27...\n",
      "Data for 2024-02-27 scraped and saved in 157.01 seconds\n",
      "Scraping data for 2024-02-28...\n",
      "Data for 2024-02-28 scraped and saved in 136.64 seconds\n",
      "Scraping data for 2024-02-29...\n",
      "Data for 2024-02-29 scraped and saved in 122.91 seconds\n",
      "Scraping data for 2024-03-01...\n",
      "Data for 2024-03-01 scraped and saved in 107.59 seconds\n",
      "Scraping data for 2024-03-02...\n",
      "Data for 2024-03-02 scraped and saved in 81.12 seconds\n",
      "Scraping data for 2024-03-03...\n",
      "Data for 2024-03-03 scraped and saved in 130.67 seconds\n",
      "Scraping data for 2024-03-04...\n",
      "Data for 2024-03-04 scraped and saved in 189.27 seconds\n",
      "Scraping data for 2024-03-05...\n",
      "Data for 2024-03-05 scraped and saved in 121.20 seconds\n",
      "Scraping data for 2024-03-06...\n",
      "Data for 2024-03-06 scraped and saved in 118.85 seconds\n",
      "Scraping data for 2024-03-07...\n",
      "Data for 2024-03-07 scraped and saved in 270.64 seconds\n",
      "Scraping data for 2024-03-08...\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/app-root/app-history/one-column-layout/wu-header/sidenav/mat-sidenav-container/mat-sidenav-content/div[2]/section/div[2]/div[1]/div[5]/div[1]/div/lib-city-history-observation/div/div[2]\"}\n  (Session info: chrome-headless-shell=122.0.6261.129); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n0   chromedriver                        0x000000010276853c chromedriver + 3966268\n1   chromedriver                        0x0000000102760ac8 chromedriver + 3934920\n2   chromedriver                        0x00000001023e3da0 chromedriver + 277920\n3   chromedriver                        0x0000000102426394 chromedriver + 549780\n4   chromedriver                        0x000000010245ebf0 chromedriver + 781296\n5   chromedriver                        0x000000010241afb0 chromedriver + 503728\n6   chromedriver                        0x000000010241ba28 chromedriver + 506408\n7   chromedriver                        0x000000010272d724 chromedriver + 3725092\n8   chromedriver                        0x0000000102731c18 chromedriver + 3742744\n9   chromedriver                        0x000000010271620c chromedriver + 3629580\n10  chromedriver                        0x0000000102732714 chromedriver + 3745556\n11  chromedriver                        0x0000000102709584 chromedriver + 3577220\n12  chromedriver                        0x0000000102750f74 chromedriver + 3870580\n13  chromedriver                        0x0000000102751118 chromedriver + 3871000\n14  chromedriver                        0x0000000102760738 chromedriver + 3934008\n15  libsystem_pthread.dylib             0x000000019e87c26c _pthread_start + 148\n16  libsystem_pthread.dylib             0x000000019e87708c thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mf/txv8p7fx2yz68v4bx9pfbxf80000gn/T/ipykernel_2718/2549369722.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Locate the table element at the bottom of the page using your specified XPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mtable_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xpath'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/html/body/app-root/app-history/one-column-layout/wu-header/sidenav/mat-sidenav-container/mat-sidenav-content/div[2]/section/div[2]/div[1]/div[5]/div[1]/div/lib-city-history-observation/div/div[2]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Extract the text from the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'[name=\"{value}\"]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFIND_ELEMENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"using\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/app-root/app-history/one-column-layout/wu-header/sidenav/mat-sidenav-container/mat-sidenav-content/div[2]/section/div[2]/div[1]/div[5]/div[1]/div/lib-city-history-observation/div/div[2]\"}\n  (Session info: chrome-headless-shell=122.0.6261.129); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n0   chromedriver                        0x000000010276853c chromedriver + 3966268\n1   chromedriver                        0x0000000102760ac8 chromedriver + 3934920\n2   chromedriver                        0x00000001023e3da0 chromedriver + 277920\n3   chromedriver                        0x0000000102426394 chromedriver + 549780\n4   chromedriver                        0x000000010245ebf0 chromedriver + 781296\n5   chromedriver                        0x000000010241afb0 chromedriver + 503728\n6   chromedriver                        0x000000010241ba28 chromedriver + 506408\n7   chromedriver                        0x000000010272d724 chromedriver + 3725092\n8   chromedriver                        0x0000000102731c18 chromedriver + 3742744\n9   chromedriver                        0x000000010271620c chromedriver + 3629580\n10  chromedriver                        0x0000000102732714 chromedriver + 3745556\n11  chromedriver                        0x0000000102709584 chromedriver + 3577220\n12  chromedriver                        0x0000000102750f74 chromedriver + 3870580\n13  chromedriver                        0x0000000102751118 chromedriver + 3871000\n14  chromedriver                        0x0000000102760738 chromedriver + 3934008\n15  libsystem_pthread.dylib             0x000000019e87c26c _pthread_start + 148\n16  libsystem_pthread.dylib             0x000000019e87708c thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "#3.15 getting all data from dates:\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Function to create a folder if it doesn't exist\n",
    "def create_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome in headless mode (without a graphical user interface)\n",
    "chrome_service = ChromeService(executable_path='/Users/samdvorin/Desktop/code/542/weather-prediction/chromedriver')  # Replace with the path to your chromedriver executable\n",
    "\n",
    "# Specify the folder name to save all text files\n",
    "output_folder = \"nyc_weather_data\"\n",
    "create_folder(output_folder)\n",
    "\n",
    "# Loop through dates from February 1 to March 15\n",
    "start_date = datetime(2024, 2, 19)\n",
    "end_date = datetime(2024, 3, 16)  # March 15 + 1 day\n",
    "current_date = start_date\n",
    "\n",
    "while current_date < end_date:\n",
    "    current_date_str = current_date.strftime('%Y-%m-%d')\n",
    "    print(f\"Scraping data for {current_date_str}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "    url = f'https://www.wunderground.com/history/daily/us/ny/new-york-city/KLGA/date/{current_date_str}'\n",
    "    driver.get(url)\n",
    "\n",
    "    # Locate the table element at the bottom of the page using your specified XPath\n",
    "    table_element = driver.find_element('xpath', '/html/body/app-root/app-history/one-column-layout/wu-header/sidenav/mat-sidenav-container/mat-sidenav-content/div[2]/section/div[2]/div[1]/div[5]/div[1]/div/lib-city-history-observation/div/div[2]')\n",
    "\n",
    "    # Extract the text from the table\n",
    "    table_text = table_element.text\n",
    "\n",
    "    # Save the text to a file in the output folder\n",
    "    with open(os.path.join(output_folder, f\"{current_date.strftime('%Y-%m-%d')}.txt\"), 'w') as file:\n",
    "        file.write(table_text)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"Data for {current_date_str} scraped and saved in {duration:.2f} seconds\")\n",
    "\n",
    "    # Move to the next date\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ERROR ON FEB 18 loook into it!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for 2024-03-09...\n",
      "Data for 2024-03-09 scraped and saved in 129.43 seconds\n",
      "Scraping data for 2024-03-10...\n",
      "Data for 2024-03-10 scraped and saved in 122.27 seconds\n",
      "Scraping data for 2024-03-11...\n",
      "Data for 2024-03-11 scraped and saved in 134.90 seconds\n",
      "Scraping data for 2024-03-12...\n",
      "Data for 2024-03-12 scraped and saved in 254.99 seconds\n",
      "Scraping data for 2024-03-13...\n",
      "Data for 2024-03-13 scraped and saved in 272.75 seconds\n",
      "Scraping data for 2024-03-14...\n",
      "Data for 2024-03-14 scraped and saved in 119.20 seconds\n",
      "Scraping data for 2024-03-15...\n",
      "Data for 2024-03-15 scraped and saved in 188.98 seconds\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Function to create a folder if it doesn't exist\n",
    "def create_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome in headless mode (without a graphical user interface)\n",
    "chrome_service = ChromeService(executable_path='/Users/samdvorin/Desktop/code/542/weather-prediction/chromedriver')  # Replace with the path to your chromedriver executable\n",
    "\n",
    "# Specify the folder name to save all text files\n",
    "output_folder = \"nyc_weather_data\"\n",
    "create_folder(output_folder)\n",
    "\n",
    "# Loop through dates from February 1 to March 15\n",
    "start_date = datetime(2024, 2, 1)\n",
    "end_date = datetime(2024, 3, 16)  # March 15 + 1 day\n",
    "current_date = start_date\n",
    "\n",
    "while current_date < end_date:\n",
    "    current_date_str = current_date.strftime('%Y-%m-%d')\n",
    "    print(f\"Scraping data for {current_date_str}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "        url = f'https://www.wunderground.com/history/daily/us/ny/new-york-city/KLGA/date/{current_date_str}'\n",
    "        driver.get(url)\n",
    "\n",
    "        # Locate the table element at the bottom of the page using your specified XPath\n",
    "        table_element = driver.find_element('xpath', '/html/body/app-root/app-history/one-column-layout/wu-header/sidenav/mat-sidenav-container/mat-sidenav-content/div[2]/section/div[2]/div[1]/div[5]/div[1]/div/lib-city-history-observation/div/div[2]')\n",
    "\n",
    "        # Extract the text from the table\n",
    "        table_text = table_element.text\n",
    "\n",
    "        # Save the text to a file in the output folder\n",
    "        with open(os.path.join(output_folder, f\"{current_date.strftime('%Y-%m-%d')}.txt\"), 'w') as file:\n",
    "            file.write(table_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for {current_date_str}: {e}\")\n",
    "    finally:\n",
    "        if 'driver' in locals():\n",
    "            driver.quit()\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"Data for {current_date_str} scraped and saved in {duration:.2f} seconds\")\n",
    "\n",
    "    # Move to the next date\n",
    "    current_date += timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model to predict temp line based on the input so far, so train it to predict next temp values at next time step based on the past rows\n",
    "# basically train it to find next row\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8433822212b79f5d8b3452ec504986410bf31415c55c9cbd3d55cd029f0ca8d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
